{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def util_pattern_space(time_series, lag, dim):\n",
    "    \"\"\"Create a set of sequences with given lag and dimension\n",
    "\n",
    "    Args:\n",
    "       time_series: Vector or string of the sample data\n",
    "       lag: Lag between beginning of sequences\n",
    "       dim: Dimension (number of patterns)\n",
    "\n",
    "    Returns:\n",
    "        2D array of vectors\n",
    "\n",
    "    \"\"\"\n",
    "    n = len(time_series)\n",
    "\n",
    "    if lag * dim > n:\n",
    "        raise Exception('Result matrix exceeded size limit, try to change lag or dim.')\n",
    "    elif lag < 1:\n",
    "        raise Exception('Lag should be greater or equal to 1.')\n",
    "\n",
    "    pattern_space = np.empty((n - lag * (dim - 1), dim))\n",
    "    for i in range(n - lag * (dim - 1)):\n",
    "        for j in range(dim):\n",
    "            pattern_space[i][j] = time_series[i + j * lag]\n",
    "\n",
    "    return pattern_space\n",
    "\n",
    "\n",
    "def util_standardize_signal(time_series):\n",
    "    return (time_series - np.mean(time_series)) / np.std(time_series)\n",
    "\n",
    "\n",
    "def util_granulate_time_series(time_series, scale):\n",
    "    \"\"\"Extract coarse-grained time series\n",
    "\n",
    "    Args:\n",
    "        time_series: Time series\n",
    "        scale: Scale factor\n",
    "\n",
    "    Returns:\n",
    "        Vector of coarse-grained time series with given scale factor\n",
    "    \"\"\"\n",
    "    n = len(time_series)\n",
    "    b = int(np.fix(n / scale))\n",
    "    cts = [0] * b\n",
    "    for i in range(b):\n",
    "        cts[i] = np.mean(time_series[i * scale: (i + 1) * scale])\n",
    "    return cts\n",
    "\n",
    "\n",
    "def shannon_entropy(time_series):\n",
    "    \"\"\"Return the Shannon Entropy of the sample data.\n",
    "\n",
    "    Args:\n",
    "        time_series: Vector or string of the sample data\n",
    "\n",
    "    Returns:\n",
    "        The Shannon Entropy as float value\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if string\n",
    "    if not isinstance(time_series, str):\n",
    "        time_series = list(time_series)\n",
    "\n",
    "    # Create a frequency data\n",
    "    data_set = list(set(time_series))\n",
    "    freq_list = []\n",
    "    for entry in data_set:\n",
    "        counter = 0.\n",
    "        for i in time_series:\n",
    "            if i == entry:\n",
    "                counter += 1\n",
    "        freq_list.append(float(counter) / len(time_series))\n",
    "\n",
    "    # Shannon entropy\n",
    "    ent = 0.0\n",
    "    for freq in freq_list:\n",
    "        ent += freq * np.log2(freq)\n",
    "    ent = -ent\n",
    "\n",
    "    return ent\n",
    "\n",
    "\n",
    "def sample_entropy(time_series, sample_length, tolerance=None):\n",
    "    \"\"\"Calculate and return Sample Entropy of the given time series.\n",
    "    Distance between two vectors defined as Euclidean distance and can\n",
    "    be changed in future releases\n",
    "\n",
    "    Args:\n",
    "        time_series: Vector or string of the sample data\n",
    "        sample_length: Number of sequential points of the time series\n",
    "        tolerance: Tolerance (default = 0.1...0.2 * std(time_series))\n",
    "\n",
    "    Returns:\n",
    "        Vector containing Sample Entropy (float)\n",
    "\n",
    "    References:\n",
    "        [1] http://en.wikipedia.org/wiki/Sample_Entropy\n",
    "        [2] http://physionet.incor.usp.br/physiotools/sampen/\n",
    "        [3] Madalena Costa, Ary Goldberger, CK Peng. Multiscale entropy analysis\n",
    "            of biological signals\n",
    "    \"\"\"\n",
    "    if tolerance is None:\n",
    "        tolerance = 0.1 * np.std(time_series)\n",
    "\n",
    "    n = len(time_series)\n",
    "    prev = np.zeros(n)\n",
    "    curr = np.zeros(n)\n",
    "    A = np.zeros((sample_length, 1))  # number of matches for m = [1,...,template_length - 1]\n",
    "    B = np.zeros((sample_length, 1))  # number of matches for m = [1,...,template_length]\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        nj = n - i - 1\n",
    "        ts1 = time_series[i]\n",
    "        for jj in range(nj):\n",
    "            j = jj + i + 1\n",
    "            if abs(time_series[j] - ts1) < tolerance:  # distance between two vectors\n",
    "                curr[jj] = prev[jj] + 1\n",
    "                temp_ts_length = min(sample_length, curr[jj])\n",
    "                for m in range(int(temp_ts_length)):\n",
    "                    A[m] += 1\n",
    "                    if j < n - 1:\n",
    "                        B[m] += 1\n",
    "            else:\n",
    "                curr[jj] = 0\n",
    "        for j in range(nj):\n",
    "            prev[j] = curr[j]\n",
    "\n",
    "    N = n * (n - 1) / 2\n",
    "    B = np.vstack(([N], B[:sample_length - 1]))\n",
    "    similarity_ratio = A / B\n",
    "    se = - np.log(similarity_ratio)\n",
    "    se = np.reshape(se, -1)\n",
    "    return se\n",
    "\n",
    "\n",
    "def multiscale_entropy(time_series, sample_length, tolerance):\n",
    "    \"\"\"Calculate the Multiscale Entropy of the given time series considering\n",
    "    different time-scales of the time series.\n",
    "\n",
    "    Args:\n",
    "        time_series: Time series for analysis\n",
    "        sample_length: Bandwidth or group of points\n",
    "        tolerance: Tolerance (default = 0.1...0.2 * std(time_series))\n",
    "\n",
    "    Returns:\n",
    "        Vector containing Multiscale Entropy\n",
    "\n",
    "    Reference:\n",
    "        [1] http://en.pudn.com/downloads149/sourcecode/math/detail646216_en.html\n",
    "    \"\"\"\n",
    "    n = len(time_series)\n",
    "    mse = np.zeros((1, sample_length))\n",
    "\n",
    "    for i in range(sample_length):\n",
    "        b = int(np.fix(n / (i + 1)))\n",
    "        temp_ts = [0] * int(b)\n",
    "        for j in range(b):\n",
    "            num = sum(time_series[j * (i + 1): (j + 1) * (i + 1)])\n",
    "            den = i + 1\n",
    "            temp_ts[j] = float(num) / float(den)\n",
    "        se = sample_entropy(temp_ts, 1, tolerance)\n",
    "        mse[0, i] = se\n",
    "\n",
    "    return mse[0]\n",
    "\n",
    "\n",
    "def permutation_entropy(time_series, m, delay):\n",
    "    \"\"\"Calculate the Permutation Entropy\n",
    "\n",
    "    Args:\n",
    "        time_series: Time series for analysis\n",
    "        m: Order of permutation entropy\n",
    "        delay: Time delay\n",
    "\n",
    "    Returns:\n",
    "        Vector containing Permutation Entropy\n",
    "\n",
    "    Reference:\n",
    "        [1] Massimiliano Zanin et al. Permutation Entropy and Its Main Biomedical and Econophysics Applications:\n",
    "            A Review. http://www.mdpi.com/1099-4300/14/8/1553/pdf\n",
    "        [2] Christoph Bandt and Bernd Pompe. Permutation entropy — a natural complexity\n",
    "            measure for time series. http://stubber.math-inf.uni-greifswald.de/pub/full/prep/2001/11.pdf\n",
    "        [3] http://www.mathworks.com/matlabcentral/fileexchange/37289-permutation-entropy/content/pec.m\n",
    "    \"\"\"\n",
    "    n = len(time_series)\n",
    "    permutations = np.array(list(itertools.permutations(range(m))))\n",
    "    c = [0] * len(permutations)\n",
    "\n",
    "    for i in range(n - delay * (m - 1)):\n",
    "        # sorted_time_series =    np.sort(time_series[i:i+delay*m:delay], kind='quicksort')\n",
    "        sorted_index_array = np.array(np.argsort(time_series[i:i + delay * m:delay], kind='quicksort'))\n",
    "        for j in range(len(permutations)):\n",
    "            if abs(permutations[j] - sorted_index_array).any() == 0:\n",
    "                c[j] += 1\n",
    "\n",
    "    c = [element for element in c if element != 0]\n",
    "    p = np.divide(np.array(c), float(sum(c)))\n",
    "    pe = -sum(p * np.log(p))\n",
    "    return pe\n",
    "\n",
    "\n",
    "def multiscale_permutation_entropy(time_series, m, delay, scale):\n",
    "    \"\"\"Calculate the Multiscale Permutation Entropy\n",
    "\n",
    "    Args:\n",
    "        time_series: Time series for analysis\n",
    "        m: Order of permutation entropy\n",
    "        delay: Time delay\n",
    "        scale: Scale factor\n",
    "\n",
    "    Returns:\n",
    "        Vector containing Multiscale Permutation Entropy\n",
    "\n",
    "    Reference:\n",
    "        [1] Francesco Carlo Morabito et al. Multivariate Multi-Scale Permutation Entropy for\n",
    "            Complexity Analysis of Alzheimer’s Disease EEG. www.mdpi.com/1099-4300/14/7/1186\n",
    "        [2] http://www.mathworks.com/matlabcentral/fileexchange/37288-multiscale-permutation-entropy-mpe/content/MPerm.m\n",
    "    \"\"\"\n",
    "    mspe = []\n",
    "    for i in range(scale):\n",
    "        coarse_time_series = util_granulate_time_series(time_series, i + 1)\n",
    "        pe = permutation_entropy(coarse_time_series, m, delay)\n",
    "        mspe.append(pe)\n",
    "    return mspe\n",
    "\n",
    "\n",
    "# TODO add tests\n",
    "def composite_multiscale_entropy(time_series, sample_length, scale):\n",
    "    \"\"\"Calculate the Composite Multiscale Entropy of the given time series.\n",
    "\n",
    "    Args:\n",
    "        time_series: Time series for analysis\n",
    "        sample_length: Number of sequential points of the time series\n",
    "        scale: Scale factor\n",
    "\n",
    "    Returns:\n",
    "        Vector containing Composite Multiscale Entropy\n",
    "\n",
    "    Reference:\n",
    "        [1] Wu, Shuen-De, et al. \"Time series analysis using\n",
    "            composite multiscale entropy.\" Entropy 15.3 (2013): 1069-1084.\n",
    "    \"\"\"\n",
    "    cmse = np.zeros((1, scale))\n",
    "    r = np.std(time_series) * 0.15\n",
    "\n",
    "    for i in range(scale):\n",
    "        for j in range(i):\n",
    "            tmp = util_granulate_time_series(time_series[j:], i + 1)\n",
    "            cmse[i] += sample_entropy(tmp, sample_length, r) / (i + 1)\n",
    "\n",
    "    return cmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
